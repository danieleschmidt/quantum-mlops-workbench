# Quantum Machine Learning CI/CD Pipeline
# 
# This workflow provides comprehensive CI/CD for quantum ML projects with:
# - Multi-framework testing (PennyLane, Qiskit, Cirq)
# - Quantum simulator validation
# - Optional real hardware testing
# - Quantum-specific metrics collection
# - Artifact management for quantum models

name: Quantum ML CI/CD

on:
  push:
    branches: [ main, develop, 'feature/**' ]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - 'requirements*.txt'
      - '.github/workflows/quantum-ml-ci.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - 'requirements*.txt'
  schedule:
    # Run nightly tests at 2 AM UTC to test hardware backends
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_hardware:
        description: 'Test on real quantum hardware'
        required: false
        default: false
        type: boolean
      quantum_backends:
        description: 'Comma-separated list of quantum backends to test'
        required: false
        default: 'pennylane,qiskit,cirq'
        type: string

env:
  PYTHONPATH: ${{ github.workspace }}/src
  QUANTUM_CI_MODE: true
  MLFLOW_TRACKING_URI: file://./mlruns
  
  # Quantum-specific configuration
  QUANTUM_TIMEOUT: 300  # 5 minutes for quantum operations
  QUANTUM_MAX_QUBITS: 20  # Limit for CI testing
  QUANTUM_SHOTS: 1000  # Default shots for hardware testing

jobs:
  # Static analysis and code quality
  code-quality:
    name: Code Quality & Static Analysis
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better analysis
    
    - name: Setup Python Environment
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
    
    - name: Run Pre-commit Hooks
      uses: pre-commit/action@v3.0.1
      with:
        extra_args: --all-files
    
    - name: Type Checking with MyPy
      run: |
        mypy src/ --config-file pyproject.toml
    
    - name: Security Scanning with Bandit
      run: |
        bandit -r src/ -f json -o bandit-report.json
        bandit -r src/ --severity-level medium
    
    - name: Dependency Security Check
      run: |
        safety check --json --output safety-report.json || true
        safety check --short-report
    
    - name: Upload Security Reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 30

  # Unit tests with quantum simulators
  quantum-unit-tests:
    name: Quantum Unit Tests
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']
        quantum-framework: ['pennylane', 'qiskit', 'cirq']
        exclude:
          # Reduce matrix size for faster CI
          - python-version: '3.9'
            quantum-framework: 'cirq'
          - python-version: '3.12'
            quantum-framework: 'cirq'
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Setup Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install Quantum Framework Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,${{ matrix.quantum-framework }}]"
    
    - name: Validate Quantum Environment
      run: |
        python -c "import quantum_mlops; print(f'Quantum MLOps v{quantum_mlops.__version__}')"
        python -c "
        import quantum_mlops.testing as qt
        qt.validate_quantum_environment('${{ matrix.quantum-framework }}')
        "
    
    - name: Run Unit Tests
      run: |
        pytest tests/unit/ \
          --cov=src/quantum_mlops \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --junit-xml=pytest-results-${{ matrix.python-version }}-${{ matrix.quantum-framework }}.xml \
          -v \
          --tb=short \
          -m "not (hardware or slow)"
    
    - name: Run Quantum-Specific Tests
      run: |
        pytest tests/quantum/ \
          --quantum-backend=${{ matrix.quantum-framework }}-simulator \
          --junit-xml=quantum-tests-${{ matrix.python-version }}-${{ matrix.quantum-framework }}.xml \
          -v \
          --tb=short \
          -m "simulation and not hardware"
    
    - name: Generate Quantum Metrics Report
      if: always()
      run: |
        python -m quantum_mlops.testing.metrics \
          --framework ${{ matrix.quantum-framework }} \
          --output quantum-metrics-${{ matrix.python-version }}-${{ matrix.quantum-framework }}.json
    
    - name: Upload Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}-${{ matrix.quantum-framework }}
        path: |
          pytest-results-*.xml
          quantum-tests-*.xml
          quantum-metrics-*.json
          htmlcov/
        retention-days: 30
    
    - name: Upload Coverage to Codecov
      uses: codecov/codecov-action@v4
      if: matrix.python-version == '3.11' && matrix.quantum-framework == 'pennylane'
      with:
        file: coverage.xml
        flags: unittests
        name: codecov-umbrella

  # Integration tests with real quantum backends (optional)
  quantum-hardware-tests:
    name: Quantum Hardware Integration Tests
    runs-on: ubuntu-latest
    if: |
      (github.ref == 'refs/heads/main' && github.event_name == 'push') ||
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' && inputs.test_hardware)
    needs: [code-quality, quantum-unit-tests]
    strategy:
      fail-fast: false
      matrix:
        backend:
          - name: "AWS Braket"
            provider: "aws"
            device: "sv1"  # State vector simulator (free)
          - name: "IBM Quantum"
            provider: "ibm"
            device: "ibmq_qasm_simulator"  # Free simulator
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Setup Python Environment
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,all]"
    
    - name: Configure Quantum Backend Credentials
      run: |
        mkdir -p ~/.quantum
        echo "Setting up ${{ matrix.backend.provider }} credentials..."
        
        # AWS Braket configuration
        if [ "${{ matrix.backend.provider }}" = "aws" ]; then
          aws configure set aws_access_key_id "${{ secrets.AWS_ACCESS_KEY_ID }}"
          aws configure set aws_secret_access_key "${{ secrets.AWS_SECRET_ACCESS_KEY }}"
          aws configure set default.region us-east-1
        fi
        
        # IBM Quantum configuration
        if [ "${{ matrix.backend.provider }}" = "ibm" ]; then
          echo "IBM_QUANTUM_TOKEN=${{ secrets.IBM_QUANTUM_TOKEN }}" >> $GITHUB_ENV
        fi
    
    - name: Test Quantum Backend Connectivity
      timeout-minutes: 5
      run: |
        python -c "
        import quantum_mlops.testing as qt
        result = qt.test_backend_connectivity('${{ matrix.backend.provider }}', '${{ matrix.backend.device }}')
        print(f'Backend connectivity test: {\"PASSED\" if result else \"FAILED\"}')"
    
    - name: Run Hardware Integration Tests
      timeout-minutes: 15
      run: |
        pytest tests/quantum/ \
          --quantum-backend=${{ matrix.backend.provider }} \
          --quantum-device=${{ matrix.backend.device }} \
          --quantum-shots=${{ env.QUANTUM_SHOTS }} \
          --timeout=${{ env.QUANTUM_TIMEOUT }} \
          --junit-xml=hardware-tests-${{ matrix.backend.provider }}.xml \
          -v \
          --tb=short \
          -m "hardware and not slow" \
          || echo "Hardware tests completed with issues"
    
    - name: Collect Hardware Metrics
      if: always()
      run: |
        python -m quantum_mlops.testing.hardware_metrics \
          --backend ${{ matrix.backend.provider }} \
          --device ${{ matrix.backend.device }} \
          --output hardware-metrics-${{ matrix.backend.provider }}.json
    
    - name: Upload Hardware Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: hardware-test-results-${{ matrix.backend.provider }}
        path: |
          hardware-tests-*.xml
          hardware-metrics-*.json
        retention-days: 7

  # Performance benchmarking and regression testing
  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest-4-cores
    needs: [quantum-unit-tests]
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Need history for performance comparison
    
    - name: Setup Python Environment
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,all]"
        pip install pytest-benchmark memory-profiler
    
    - name: Run Performance Benchmarks
      run: |
        pytest tests/benchmarks/ \
          --benchmark-only \
          --benchmark-json=benchmark-results.json \
          --benchmark-warmup=on \
          --benchmark-warmup-iterations=2 \
          --benchmark-min-rounds=5 \
          -v
    
    - name: Memory Usage Profiling
      run: |
        python -m memory_profiler scripts/profile_memory.py > memory-profile.txt
    
    - name: Quantum Circuit Complexity Analysis
      run: |
        python -m quantum_mlops.analysis.complexity \
          --output circuit-complexity.json \
          --max-qubits ${{ env.QUANTUM_MAX_QUBITS }}
    
    - name: Performance Regression Check
      run: |
        python scripts/check_performance_regression.py \
          --current benchmark-results.json \
          --threshold 1.2  # 20% regression threshold
    
    - name: Upload Benchmark Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-benchmarks
        path: |
          benchmark-results.json
          memory-profile.txt
          circuit-complexity.json
        retention-days: 30

  # Container and deployment testing
  container-tests:
    name: Container & Deployment Tests
    runs-on: ubuntu-latest
    needs: [quantum-unit-tests]
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build Container Image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        tags: quantum-mlops:ci
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          PYTHON_VERSION=3.11
          QUANTUM_FRAMEWORK=pennylane
    
    - name: Test Container Functionality
      run: |
        docker run --rm quantum-mlops:ci python -c "
        import quantum_mlops
        print(f'Container test passed: v{quantum_mlops.__version__}')
        quantum_mlops.testing.validate_quantum_environment('pennylane')
        "
    
    - name: Security Scan Container
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: quantum-mlops:ci
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Container Security Results
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  # Aggregate results and generate reports
  aggregate-results:
    name: Aggregate Results & Generate Reports
    runs-on: ubuntu-latest
    needs: [code-quality, quantum-unit-tests, performance-benchmarks, container-tests]
    if: always()
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Setup Python Environment
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Download All Artifacts
      uses: actions/download-artifact@v4
      with:
        path: ci-artifacts
    
    - name: Generate CI Summary Report
      run: |
        python scripts/generate_ci_report.py \
          --artifacts-dir ci-artifacts \
          --output ci-summary.html \
          --format html
    
    - name: Create GitHub Summary
      run: |
        echo "## ðŸš€ Quantum ML CI/CD Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Test Results Overview" >> $GITHUB_STEP_SUMMARY
        python scripts/create_github_summary.py >> $GITHUB_STEP_SUMMARY
    
    - name: Comment PR with Results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('ci-summary.html', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## Quantum ML CI/CD Results\n\n${summary}`
          });
    
    - name: Upload CI Summary
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: ci-summary
        path: |
          ci-summary.html
          ci-artifacts/
        retention-days: 30

# Optional: Deploy to staging environment
# Uncomment and configure for your deployment needs
#  deploy-staging:
#    name: Deploy to Staging
#    runs-on: ubuntu-latest
#    needs: [aggregate-results]
#    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
#    environment: staging
#    
#    steps:
#    - name: Deploy to Quantum ML Staging
#      run: |
#        echo "Deploying to staging environment..."
#        # Add your deployment steps here